<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Decision Tree and k-Nearest Neighbors Learning | Dash's Blog</title><meta name="author" content="Dash"><meta name="copyright" content="Dash"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Entropy1. Shannon information  I &#x3D; -\log_2{p} $ p $ is the probability of the event Event with smaller probability contains more information. Logrithm base is 2 beacause in information technology 1 bi">
<meta property="og:type" content="article">
<meta property="og:title" content="Decision Tree and k-Nearest Neighbors Learning">
<meta property="og:url" content="http://example.com/2020/11/18/learning/ml/decision_tree_and_knn_learning/index.html">
<meta property="og:site_name" content="Dash&#39;s Blog">
<meta property="og:description" content="Entropy1. Shannon information  I &#x3D; -\log_2{p} $ p $ is the probability of the event Event with smaller probability contains more information. Logrithm base is 2 beacause in information technology 1 bi">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:published_time" content="2020-11-17T16:00:00.000Z">
<meta property="article:modified_time" content="2024-01-20T13:36:11.509Z">
<meta property="article:author" content="Dash">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2020/11/18/learning/ml/decision_tree_and_knn_learning/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Decision Tree and k-Nearest Neighbors Learning',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-20 21:36:11'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">76</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Dash's Blog"><span class="site-name">Dash's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Decision Tree and k-Nearest Neighbors Learning</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-11-17T16:00:00.000Z" title="发表于 2020-11-18 00:00:00">2020-11-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-20T13:36:11.509Z" title="更新于 2024-01-20 21:36:11">2024-01-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">学习记录</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Decision Tree and k-Nearest Neighbors Learning"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h2><p>1. Shannon information</p>
<script type="math/tex; mode=display">
I = -\log_2{p}</script><ul>
<li>$ p $ is the probability of the event</li>
<li>Event with smaller probability contains more information.</li>
<li>Logrithm base is 2 beacause in information technology 1 bit represents “0” or “1”.</li>
</ul>
<p>It can also be regarded as how many bits we need to represent a random variable</p>
<script type="math/tex; mode=display">
\#bits = \log_2{1\over{p}}</script><p>For example, when one variable has 8 possibilities. Each of them has a probability of 1/8. Then we need $ \log_2{8} = 3 $ bits to represent the variable.</p>
<p>2. Shannon entropy</p>
<script type="math/tex; mode=display">
H = - \sum_{i=1}^{n}{p_i\log_{2}{p}_i}</script><ul>
<li>$ H $ is sum of all possible events</li>
<li><code>H = 1</code> means completly uncertain about the result. <code>H = 0</code> means the result is known.</li>
</ul>
<p>For example, if we throw a coin, it will have 2 results, both probabilities is 0.5.</p>
<script type="math/tex; mode=display">
H = -0.5 \times \log_2{0.5} - 0.5 \times \log_2{0.5} = 1</script><p>The result is totally uncertain.</p>
<p>3. Information gain</p>
<script type="math/tex; mode=display">
IG(T, a) = H(T) - H(T|a) \\
H (T|a) = -\sum_{x \in {a}, y \in{T}}{p(x, y)\log{p(x, y) \over {p(x)}}}</script><ul>
<li>$ H(T|a) $ is the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Conditional_entropy">conditional entropy</a> of T given the value of attribute a.</li>
</ul>
<h2 id="ID3-Iterative-Dichotomiser-3-Algorithm"><a href="#ID3-Iterative-Dichotomiser-3-Algorithm" class="headerlink" title="ID3 (Iterative Dichotomiser 3) Algorithm"></a>ID3 (Iterative Dichotomiser 3) Algorithm</h2><p>ID3 is an algorithm invented by Ross Quinlan used to generate a decision tree from a dataset.</p>
<p>It can be used for dataset with categorical features like:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Day</th>
<th style="text-align:center">Outlook</th>
<th style="text-align:center">Temperature</th>
<th style="text-align:center">Humidity</th>
<th style="text-align:center">Wind</th>
<th style="text-align:center">Play ball</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">D1</td>
<td style="text-align:center">Sunny</td>
<td style="text-align:center">Hot</td>
<td style="text-align:center">High</td>
<td style="text-align:center">Weak</td>
<td style="text-align:center">No (-)</td>
</tr>
<tr>
<td style="text-align:center">D2</td>
<td style="text-align:center">Sunny</td>
<td style="text-align:center">Hot</td>
<td style="text-align:center">High</td>
<td style="text-align:center">Strong</td>
<td style="text-align:center">No (-)</td>
</tr>
<tr>
<td style="text-align:center">D3</td>
<td style="text-align:center">Overcast</td>
<td style="text-align:center">Hot</td>
<td style="text-align:center">High</td>
<td style="text-align:center">Weak</td>
<td style="text-align:center">Yes (+)</td>
</tr>
<tr>
<td style="text-align:center">D4</td>
<td style="text-align:center">Rain</td>
<td style="text-align:center">Mild</td>
<td style="text-align:center">High</td>
<td style="text-align:center">Weak</td>
<td style="text-align:center">Yes (+)</td>
</tr>
<tr>
<td style="text-align:center">D5</td>
<td style="text-align:center">Rain</td>
<td style="text-align:center">Cool</td>
<td style="text-align:center">Normal</td>
<td style="text-align:center">Weak</td>
<td style="text-align:center">Yes (+)</td>
</tr>
<tr>
<td style="text-align:center">D6</td>
<td style="text-align:center">Rain</td>
<td style="text-align:center">Cool</td>
<td style="text-align:center">Normal</td>
<td style="text-align:center">Strong</td>
<td style="text-align:center">No (-)</td>
</tr>
<tr>
<td style="text-align:center">D7</td>
<td style="text-align:center">Overcast</td>
<td style="text-align:center">Cool</td>
<td style="text-align:center">Normal</td>
<td style="text-align:center">Strong</td>
<td style="text-align:center">Yes (+)</td>
</tr>
<tr>
<td style="text-align:center">D8</td>
<td style="text-align:center">Sunny</td>
<td style="text-align:center">Mild</td>
<td style="text-align:center">High</td>
<td style="text-align:center">Weak</td>
<td style="text-align:center">No (-)</td>
</tr>
</tbody>
</table>
</div>
<p>Pseudocode:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ID3 (Examples, Target_Attribute, Attributes)</span><br><span class="line">    Create a root node for the tree</span><br><span class="line">    If all examples are positive, Return the single-node tree Root, with label = +.</span><br><span class="line">    If all examples are negative, Return the single-node tree Root, with label = -.</span><br><span class="line">    If number of predicting attributes is empty, then Return the single node tree Root,</span><br><span class="line">    with label = most common value of the target attribute in the examples.</span><br><span class="line">    Otherwise Begin</span><br><span class="line">        A ← The Attribute that best classifies examples.</span><br><span class="line">        Decision Tree attribute for Root = A.</span><br><span class="line">        For each possible value, vi, of A,</span><br><span class="line">            Add a new tree branch below Root, corresponding to the test A = vi.</span><br><span class="line">            Let Examples(vi) be the subset of examples that have the value vi for A</span><br><span class="line">            If Examples(vi) is empty</span><br><span class="line">                Then below this new branch add a leaf node with label = most common target value in the examples</span><br><span class="line">            Else below this new branch add the subtree ID3 (Examples(vi), Target_Attribute, Attributes – &#123;A&#125;)</span><br><span class="line">    End</span><br><span class="line">    Return Root</span><br></pre></td></tr></table></figure>
<p>ID3 does not guarantee an optimal solution. It can converge upon local optima. It uses a greedy strategy by selecting the locally best attribute to split the dataset on each iteration.</p>
<h2 id="C4-5-Algorithm"><a href="#C4-5-Algorithm" class="headerlink" title="C4.5 Algorithm"></a>C4.5 Algorithm</h2><p>It can be used for data with continuous features.</p>
<p>Procedure:</p>
<ol>
<li>Sort the data records by the attribute values</li>
<li>Calculate the partition point for 2 consecutive records by $ (v<em>i + v</em>{i+1})/2 $</li>
<li>Partition the records into 2 sets by that partition point</li>
<li>Calculate the entropy reduction (information gain) of the resulting partitions</li>
<li>If all partition points are calculated, choose the point that yields the highest entropy reduction. Otherwise, ad i by 1 and go back to <code>step 2</code></li>
</ol>
<p>The whole process is nearly the same as ID3 algorithm, except for continuous feature, we need to calculate the partition point. But in ID3 algorithm, we can directly use the categories to split records.</p>
<h2 id="k-Nearest-Neighbors-Algorithm"><a href="#k-Nearest-Neighbors-Algorithm" class="headerlink" title="k-Nearest Neighbors Algorithm"></a>k-Nearest Neighbors Algorithm</h2><p>Distance between instance i and j</p>
<script type="math/tex; mode=display">
d(x^{(i)}, x^{(j)}) = \sqrt{\sum_{r=1}^{n}{(f_r(x^{i})-f_r(x^{(j)}))^2}}</script><p>$f_r(x)$ is the feature value of instance $ x $.</p>
<p>To predict a new instance $ x^{(q)} $:</p>
<p>1. Continues value</p>
<script type="math/tex; mode=display">
\hat{f} \gets \frac{1}{k} \sum_{i=1}^{k}f(x^{(ki)})</script><p>2. Discrete values</p>
<script type="math/tex; mode=display">
\hat{f} \gets \text{argmax}_{v \in V} \sum_{i=1}^{k} I(f(x^{(i)}) == v)</script><p>We can also use distance weighted nearest neighbor algorithm:</p>
<script type="math/tex; mode=display">
\hat{f} \gets \frac{\sum_{i=1}^{k}{w_if(x^{(i)})}}{\sum_{i=1}^{k}{w_i}}, \ \text {where} \ w_i = \frac{1}{d(x^{(q)}, x^{(i)})^2}</script><h2 id="Evaluation-Classification"><a href="#Evaluation-Classification" class="headerlink" title="Evaluation Classification"></a>Evaluation Classification</h2><p>1. Evaluation Metrics</p>
<p><img src="evaluation_matrix.png" alt="Evaluation Metrics"></p>
<script type="math/tex; mode=display">
Accuracy = \frac{a+d}{a+b+c+d} \\
Precision = \frac{d}{b+d} \\
Sensitivity = Recall = \frac{d}{c+d} \\
Specificity = \frac{a}{a+b} \\
(False\ Positive\ Rate = 1 - Specificity)</script><p>2. Area Under ROC Curve (AUC)</p>
<p><img src="auc.png" alt="AUC"></p>
<ul>
<li>Cutoff is the threshold a classification model uses to split between 2 classes.</li>
<li>As the cutoff decreases, more and more cases are classified as 1; hence, the sensitivity increases and speificity decreases.</li>
<li>As the ROC curvebows above the diagonal, the predictive power increases. Curve 1 is better than curve 2</li>
</ul>
<h2 id="Issues-in-Decision-Tree-Learning"><a href="#Issues-in-Decision-Tree-Learning" class="headerlink" title="Issues in Decision Tree Learning"></a>Issues in Decision Tree Learning</h2><p>1. Features with many unique values</p>
<p><strong>Problem:</strong> <em>Gain</em> tends to select features with many unique values to clssify instance.</p>
<p><strong>Solution:</strong> Adjust <em>Gain</em> to <em>GainRatio</em></p>
<script type="math/tex; mode=display">
SplitInfomation(S,A) \equiv -\sum_{i=1}^{c}\frac{|S_i|}{|S|}\log_2{\frac{|S_i|}{|S|}} \\
GainRatio(S,A) = \frac{Gain(S,A)}{SplitInfomation(S,A)}</script><p>$ S $ is the set of all records in a prarent node. $ S_i $ is a subset of records that have feature $ A_i $</p>
<p>When should Gain Ratio be used in place of Gain?</p>
<ul>
<li>Compute both Gain Ratio and Gain for each feature</li>
<li>Use Gain Ratio only for features with above-average Gain</li>
</ul>
<p>2. Overfitting</p>
<p>Ways to avoid overfitting:</p>
<ul>
<li>Stop growing tree when data split is not statistically significant.</li>
<li>Grow full tree then post-prune.</li>
</ul>
<p>Selecting best tree:</p>
<ul>
<li>Measure performance over taining data</li>
<li>Measure performance over seperate validation datases</li>
<li>Add penalty against complexity</li>
</ul>
<p>3. Unknown feature values</p>
<p>Strategies to impute missing values of feature A:</p>
<ul>
<li>Use most common value of A in all instances having missing value for A</li>
<li>Within each group of instances having same target value, assign most common value of A to instances</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Dash</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2020/11/18/learning/ml/decision_tree_and_knn_learning/">http://example.com/2020/11/18/learning/ml/decision_tree_and_knn_learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Dash's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/12/30/essay/migrate_to_hugo/" title="从HEXO迁移到HUGO"><img class="cover" src="/2020/12/30/essay/migrate_to_hugo/cover.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">从HEXO迁移到HUGO</div></div></a></div><div class="next-post pull-right"><a href="/2020/11/13/learning/database/xact_and_concurrency_ctrl/" title="Transaction and Concurrency Control"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Transaction and Concurrency Control</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Dash</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">76</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">38</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yuukidach"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客，希望你能在这里找到你想要的东西。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Entropy"><span class="toc-number">1.</span> <span class="toc-text">Entropy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ID3-Iterative-Dichotomiser-3-Algorithm"><span class="toc-number">2.</span> <span class="toc-text">ID3 (Iterative Dichotomiser 3) Algorithm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#C4-5-Algorithm"><span class="toc-number">3.</span> <span class="toc-text">C4.5 Algorithm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#k-Nearest-Neighbors-Algorithm"><span class="toc-number">4.</span> <span class="toc-text">k-Nearest Neighbors Algorithm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-Classification"><span class="toc-number">5.</span> <span class="toc-text">Evaluation Classification</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Issues-in-Decision-Tree-Learning"><span class="toc-number">6.</span> <span class="toc-text">Issues in Decision Tree Learning</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/10/config/easyconnect/" title="安全地使用Easy Connect">安全地使用Easy Connect</a><time datetime="2021-10-09T21:09:17.000Z" title="发表于 2021-10-10 05:09:17">2021-10-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/10/linux/unmute_problem/" title="Cannot Unmute With Keyboard">Cannot Unmute With Keyboard</a><time datetime="2021-10-09T20:40:37.000Z" title="发表于 2021-10-10 04:40:37">2021-10-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/01/20/learning/algorithm/mst/" title="最小生成树算法">最小生成树算法</a><time datetime="2021-01-20T00:08:26.000Z" title="发表于 2021-01-20 08:08:26">2021-01-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/01/07/learning/algorithm/floyd/" title="Floyd-Warshall 算法">Floyd-Warshall 算法</a><time datetime="2021-01-07T04:44:45.000Z" title="发表于 2021-01-07 12:44:45">2021-01-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/30/essay/migrate_to_hugo/" title="从HEXO迁移到HUGO"><img src="/2020/12/30/essay/migrate_to_hugo/cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从HEXO迁移到HUGO"/></a><div class="content"><a class="title" href="/2020/12/30/essay/migrate_to_hugo/" title="从HEXO迁移到HUGO">从HEXO迁移到HUGO</a><time datetime="2020-12-30T01:32:31.000Z" title="发表于 2020-12-30 09:32:31">2020-12-30</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2024 By Dash</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>